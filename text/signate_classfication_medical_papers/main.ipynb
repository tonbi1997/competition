{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの取得、整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\DEV\\\\competition\\\\text\\\\signate_classfication_medical_papers',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\python38.zip',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\DLLs',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib',\n",
       " 'd:\\\\masa\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\masa\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\geoplot-0.4.1-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\contextily-1.0.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\mapclassify-2.3.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\descartes-1.1.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstract\"]=df[\"abstract\"].where(df[\"abstract\"].notna(),df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "0   One-year age changes in MRI brain volumes in o...   \n",
       "1   Supportive CSF biomarker evidence to enhance t...   \n",
       "2   Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   New developments in diagnosis and therapy of C...   \n",
       "4   Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                             abstract  judgement  \n",
       "id                                                                \n",
       "0   Longitudinal studies indicate that declines in...          0  \n",
       "1   The present study was undertaken to validate t...          0  \n",
       "2   Objective: To report a case series in which ba...          0  \n",
       "3   The etiology and pathogenesis of idiopathic ch...          0  \n",
       "4   Prolonged shedding of SARS-CoV-2 in an elderly...          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27145"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインストール\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip install -U fugashi ipadic \\\n",
    "#    transformers lime captum\\\n",
    "#    scikit-learn numpy --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データローラーなど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21716/21716 [00:00<00:00, 588501.19it/s]\n",
      "100%|██████████| 5429/5429 [00:00<00:00, 777773.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = [\n",
    "            {\n",
    "                'abstract': row.abstract,\n",
    "                'judgement': row.judgement\n",
    "            } for row in tqdm(df.itertuples(), total=df.shape[0])\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "train_df, eval_df = train_test_split(df, train_size=0.8)\n",
    "#eval_df, test_df = train_test_split(eval_df, train_size=0.5)\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "eval_dataset = CustomDataset(eval_df)\n",
    "#test_dataset = CustomDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 21201, 1: 515})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "l = train_df.judgement\n",
    "\n",
    "c = collections.Counter(l)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5312, 1: 117})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "l = eval_df.judgement\n",
    "\n",
    "c = collections.Counter(l)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\masa/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\5546055f03398095e385d7dc625e636cc8910bf2\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\masa/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\5546055f03398095e385d7dc625e636cc8910bf2\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\masa/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\5546055f03398095e385d7dc625e636cc8910bf2\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\masa/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\5546055f03398095e385d7dc625e636cc8910bf2\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\masa/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\5546055f03398095e385d7dc625e636cc8910bf2\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class CustomCollator():\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, examples):\n",
    "        try:\n",
    "            examples = {\n",
    "                'abstract': list(map(lambda x: x['abstract'], examples)),\n",
    "                'judgement': list(map(lambda x: x['judgement'], examples))\n",
    "            }\n",
    "        except:\n",
    "            examples = {\n",
    "                'abstract': list(map(lambda x: x['abstract'], examples))\n",
    "            }\n",
    "        encodings = self.tokenizer(examples['abstract'],\n",
    "                                   padding=True,\n",
    "                                   truncation=True,\n",
    "                                   max_length=self.max_length,\n",
    "                                   return_tensors='pt')\n",
    "        if 'judgement' in examples:\n",
    "            encodings['judgement'] = torch.tensor(examples['judgement'])\n",
    "        return encodings\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "custom_collator = CustomCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTモデルの動作デバイス\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class FocalLossWithOutOneHot(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLossWithOutOneHot, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logit = F.softmax(input, dim=1)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        logit_ls = torch.log(logit)\n",
    "        loss = F.nll_loss(logit_ls, target, reduction=\"none\")\n",
    "        view = target.size() + (1,)\n",
    "        index = target.view(*view)\n",
    "        loss = loss * (1 - logit.gather(1, index).squeeze(1)) ** self.gamma # focal loss\n",
    "        return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_categories, loss_function=None):\n",
    "        super().__init__()\n",
    "        self.bert = pretrained_model\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.linear = nn.Linear(self.hidden_size, num_categories)\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                token_type_ids=None,\n",
    "                output_attentions=False,\n",
    "                output_hidden_states=False,\n",
    "                judgement=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            position_ids=position_ids,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            output_attentions=output_attentions,\n",
    "                            output_hidden_states=output_hidden_states)\n",
    "        \n",
    "        state = outputs.last_hidden_state[:, 0, :]\n",
    "        state = self.linear(state)\n",
    "        \n",
    "        loss=None\n",
    "        if judgement is not None and self.loss_function is not None:\n",
    "            loss = self.loss_function(state, judgement)\n",
    "        \n",
    "        attentions=None\n",
    "        if output_attentions:\n",
    "            attentions=outputs.attentions\n",
    "        \n",
    "        hidden_states=None\n",
    "        if output_hidden_states:\n",
    "            hidden_states=outputs.hidden_states\n",
    "        print(state)\n",
    "        return ModelOutput(\n",
    "            logits=state,\n",
    "            loss=loss,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            attentions=attentions,\n",
    "            hidden_states=hidden_states\n",
    "        )\n",
    "\n",
    "categories = [0,1]\n",
    "loss_fct = FocalLossWithOutOneHot()\n",
    "pretrained_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "model = CustomNet(pretrained_model, len(categories), loss_fct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"output\\model\\prod\\pytorch_model.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#BERTの最上位層（１２層目）とその下の層（11層目）をアクティブにする\n",
    "for name, param in model.bert.encoder.layer[11].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for name, param in model.bert.encoder.layer[10].named_parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masa\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = transformers.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "from typing import Dict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, fbeta_score\n",
    "\n",
    "def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "    # res.predictions, res.label_idsはnumpyのarray\n",
    "    pred = res.predictions.argmax(axis=1)\n",
    "    target = res.label_ids\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    fbeta = fbeta_score(target, pred, beta = 7, average='macro')\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'fbeta' : fbeta\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./output/model',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    label_names=['judgement'],\n",
    "    lr_scheduler_type='polynomial',\n",
    "    metric_for_best_model='fbeta',\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomNet(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (loss_function): FocalLossWithOutOneHot()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=custom_collator,\n",
    "    compute_metrics=custom_compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=8)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'])\n",
    "trainer.save_model(\"output/model/prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 5429\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965a618849d4f92b5c352d15c0f97be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "preds_output = trainer.predict(eval_dataset, ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_valid = np.array(eval_df[\"judgement\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, categories):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=None)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=categories)\n",
    "    disp.plot(cmap=\"Blues\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 40834/40834 [00:00<00:00, 929861.23it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 40834\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [66], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mtest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mwhere(test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna(),test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     22\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TestDataset(test_df)\n\u001b[1;32m---> 24\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2861\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2858\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   2860\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 2861\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[0;32m   2862\u001b[0m     test_dataloader, description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPrediction\u001b[39;49m\u001b[39m\"\u001b[39;49m, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix\n\u001b[0;32m   2863\u001b[0m )\n\u001b[0;32m   2864\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[0;32m   2865\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[0;32m   2866\u001b[0m     speed_metrics(\n\u001b[0;32m   2867\u001b[0m         metric_key_prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2871\u001b[0m     )\n\u001b[0;32m   2872\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2988\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2982\u001b[0m     inputs_host \u001b[39m=\u001b[39m (\n\u001b[0;32m   2983\u001b[0m         inputs_decode\n\u001b[0;32m   2984\u001b[0m         \u001b[39mif\u001b[39;00m inputs_host \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2985\u001b[0m         \u001b[39melse\u001b[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m   2986\u001b[0m     )\n\u001b[0;32m   2987\u001b[0m \u001b[39mif\u001b[39;00m logits \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2988\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pad_across_processes(logits)\n\u001b[0;32m   2989\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_gather(logits)\n\u001b[0;32m   2990\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:3124\u001b[0m, in \u001b[0;36mTrainer._pad_across_processes\u001b[1;34m(self, tensor, pad_index)\u001b[0m\n\u001b[0;32m   3122\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[0;32m   3123\u001b[0m \u001b[39m# Gather all sizes\u001b[39;00m\n\u001b[1;32m-> 3124\u001b[0m size \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(tensor\u001b[39m.\u001b[39;49mshape, device\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdevice)[\u001b[39mNone\u001b[39;00m]\n\u001b[0;32m   3125\u001b[0m sizes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_gather(size)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m   3127\u001b[0m max_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(s[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m sizes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = [\n",
    "            {\n",
    "                'abstract': row.abstract\n",
    "            } for row in tqdm(df.itertuples(), total=df.shape[0])\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\", index_col=0)\n",
    "test_df[\"abstract\"]=test_df[\"abstract\"].where(test_df[\"abstract\"].notna(),test_df[\"title\"])\n",
    "\n",
    "test_dataset = TestDataset(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 2\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "result = trainer.predict(test_dataset[0:2], ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 5.5383935, -5.2530723],\n",
       "       [ 3.457717 , -2.8394465]], dtype=float32), label_ids=None, metrics={'test_runtime': 0.7026, 'test_samples_per_second': 2.846, 'test_steps_per_second': 1.423})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/model/prod\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "tokenizer config file saved in output/model/prod\\tokenizer_config.json\n",
      "Special tokens file saved in output/model/prod\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"output/model/prod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmitDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = [\n",
    "            {\n",
    "                'abstract': row.abstract\n",
    "            } for row in tqdm(df.itertuples(), total=df.shape[0])\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "100%|██████████| 40834/40834 [00:00<00:00, 314942.63it/s]\n"
     ]
    }
   ],
   "source": [
    "submit_df = pd.read_csv(\"test.csv\", index_col=0)\n",
    "submit_df[\"abstract\"]=submit_df[\"abstract\"].where(submit_df[\"abstract\"].notna(),submit_df[\"title\"])\n",
    "submit_df['judgement'] = [0] * len(submit_df)\n",
    "submit_dataset = CustomDataset(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[\"abstract\"]=submit_df[\"abstract\"].where(submit_df[\"abstract\"].notna(),submit_df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27145</th>\n",
       "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
       "      <td>The objective of the paper is to analyse chang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27146</th>\n",
       "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
       "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147</th>\n",
       "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
       "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27148</th>\n",
       "      <td>Adaptive image segmentation for robust measure...</td>\n",
       "      <td>We present a method that significantly improve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27149</th>\n",
       "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
       "      <td>The objective of this study is to compare the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67974</th>\n",
       "      <td>Knowledge, Attitude, and Practices of Healthca...</td>\n",
       "      <td>In the current outbreak of novel coronavirus (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67975</th>\n",
       "      <td>Safety and Efficacy of Anti-Il6-Receptor Tocil...</td>\n",
       "      <td>BACKGROUND: As the novel SARS-CoV-2 pandemic o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67976</th>\n",
       "      <td>Functional imaging of head and neck tumors usi...</td>\n",
       "      <td>Positron emission tomography (PET) is an imagi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67977</th>\n",
       "      <td>Effectiveness of 3D virtual imaging</td>\n",
       "      <td>Effectiveness of 3D virtual imaging</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67978</th>\n",
       "      <td>A prospective evaluation of thallium-201 singl...</td>\n",
       "      <td>PURPOSE: The follow-up of patients with malign...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40834 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "id                                                         \n",
       "27145  Estimating the potential effects of COVID-19 p...   \n",
       "27146  Leukoerythroblastic reaction in a patient with...   \n",
       "27147  [15O]-water PET and intraoperative brain mappi...   \n",
       "27148  Adaptive image segmentation for robust measure...   \n",
       "27149  Comparison of Epidemiological Variations in CO...   \n",
       "...                                                  ...   \n",
       "67974  Knowledge, Attitude, and Practices of Healthca...   \n",
       "67975  Safety and Efficacy of Anti-Il6-Receptor Tocil...   \n",
       "67976  Functional imaging of head and neck tumors usi...   \n",
       "67977                Effectiveness of 3D virtual imaging   \n",
       "67978  A prospective evaluation of thallium-201 singl...   \n",
       "\n",
       "                                                abstract  judgement  \n",
       "id                                                                   \n",
       "27145  The objective of the paper is to analyse chang...          0  \n",
       "27146  Leukoerythroblastic reaction in a patient with...          0  \n",
       "27147  [15O]-water PET was performed on 12 patients w...          0  \n",
       "27148  We present a method that significantly improve...          0  \n",
       "27149  The objective of this study is to compare the ...          0  \n",
       "...                                                  ...        ...  \n",
       "67974  In the current outbreak of novel coronavirus (...          0  \n",
       "67975  BACKGROUND: As the novel SARS-CoV-2 pandemic o...          0  \n",
       "67976  Positron emission tomography (PET) is an imagi...          0  \n",
       "67977                Effectiveness of 3D virtual imaging          0  \n",
       "67978  PURPOSE: The follow-up of patients with malign...          0  \n",
       "\n",
       "[40834 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 40834\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546b37a181fc41b0928b9a396d496866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "result = trainer.predict(submit_dataset, ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 5.5383935, -5.2530723],\n",
       "       [ 3.457717 , -2.8394465]], dtype=float32), label_ids=None, metrics={'test_runtime': 0.7026, 'test_samples_per_second': 2.846, 'test_steps_per_second': 1.423})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m softmax_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m softmax_output \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\masa\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32md:\\masa\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1198\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1198\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49msoftmax(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, _stacklevel\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32md:\\masa\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1512\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1512\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1514\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "softmax_fn = nn.Softmax(dim=1)\n",
    "softmax_output = softmax_fn(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.5383935, -5.2530723],\n",
       "       [ 3.457717 , -2.8394465]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './input/livedoor_data.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./input/livedoor_data.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# カテゴリーのID列を付与しておく\u001b[39;00m\n\u001b[0;32m      6\u001b[0m categories \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32md:\\masa\\Anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m    186\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[1;32m--> 187\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    188\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    189\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    190\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    191\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    192\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    193\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    201\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\masa\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    799\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/livedoor_data.pickle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_pickle('./input/livedoor_data.pickle')\n",
    "# カテゴリーのID列を付与しておく\n",
    "categories = df['category'].unique().tolist()\n",
    "category2id = {cat: categories.index(cat) for cat in categories}\n",
    "df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "df.sample(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c5e9d213741e57af941aa78a333f873168089e7713d62d465ad09d7150e1980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
