{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの取得、整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\DEV\\\\competition\\\\text\\\\signate_classfication_medical_papers',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\python38.zip',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\DLLs',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib',\n",
       " 'd:\\\\masa\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\masa\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\geoplot-0.4.1-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\contextily-1.0.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\mapclassify-2.3.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\descartes-1.1.0-py3.8.egg',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'd:\\\\masa\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"abstract\"]=df[\"abstract\"].where(df[\"abstract\"].notna(),df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "0   One-year age changes in MRI brain volumes in o...   \n",
       "1   Supportive CSF biomarker evidence to enhance t...   \n",
       "2   Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   New developments in diagnosis and therapy of C...   \n",
       "4   Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                             abstract  judgement  \n",
       "id                                                                \n",
       "0   Longitudinal studies indicate that declines in...          0  \n",
       "1   The present study was undertaken to validate t...          0  \n",
       "2   Objective: To report a case series in which ba...          0  \n",
       "3   The etiology and pathogenesis of idiopathic ch...          0  \n",
       "4   Prolonged shedding of SARS-CoV-2 in an elderly...          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27145"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipython -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインストール\n",
    "#!python -m pip install --upgrade pip\n",
    "#!pip install -U fugashi ipadic \\\n",
    "#    transformers lime captum\\\n",
    "#    scikit-learn numpy --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データローラーなど"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19001/19001 [00:00<00:00, 732748.92it/s]\n",
      "100%|██████████| 4072/4072 [00:00<00:00, 816796.07it/s]\n",
      "100%|██████████| 4072/4072 [00:00<00:00, 811363.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = [\n",
    "            {\n",
    "                'abstract': row.abstract,\n",
    "                'judgement': row.judgement\n",
    "            } for row in tqdm(df.itertuples(), total=df.shape[0])\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "train_df, eval_df = train_test_split(df, train_size=0.7)\n",
    "eval_df, test_df = train_test_split(eval_df, train_size=0.5)\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "eval_dataset = CustomDataset(eval_df)\n",
    "test_dataset = CustomDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class CustomCollator():\n",
    "    def __init__(self, tokenizer, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, examples):\n",
    "        examples = {\n",
    "            'abstract': list(map(lambda x: x['abstract'], examples)),\n",
    "            'judgement': list(map(lambda x: x['judgement'], examples))\n",
    "        }\n",
    "        \n",
    "        encodings = self.tokenizer(examples['abstract'],\n",
    "                                   padding=True,\n",
    "                                   truncation=True,\n",
    "                                   max_length=self.max_length,\n",
    "                                   return_tensors='pt')\n",
    "        encodings['judgement'] = torch.tensor(examples['judgement'])\n",
    "        return encodings\n",
    "tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "custom_collator = CustomCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTモデルの動作デバイス\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_categories, loss_function=None):\n",
    "        super().__init__()\n",
    "        self.bert = pretrained_model\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.linear = nn.Linear(self.hidden_size, num_categories)\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                token_type_ids=None,\n",
    "                output_attentions=False,\n",
    "                output_hidden_states=False,\n",
    "                judgement=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            position_ids=position_ids,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            output_attentions=output_attentions,\n",
    "                            output_hidden_states=output_hidden_states)\n",
    "        \n",
    "        state = outputs.last_hidden_state[:, 0, :]\n",
    "        state = self.linear(state)\n",
    "        \n",
    "        loss=None\n",
    "        if judgement is not None and self.loss_function is not None:\n",
    "            loss = self.loss_function(state, judgement)\n",
    "        \n",
    "        attentions=None\n",
    "        if output_attentions:\n",
    "            attentions=outputs.attentions\n",
    "        \n",
    "        hidden_states=None\n",
    "        if output_hidden_states:\n",
    "            hidden_states=outputs.hidden_states\n",
    "        \n",
    "        return ModelOutput(\n",
    "            logits=state,\n",
    "            loss=loss,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            attentions=attentions,\n",
    "            hidden_states=hidden_states\n",
    "        )\n",
    "\n",
    "categories = [0,1]\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "pretrained_model = AutoModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "model = CustomNet(pretrained_model, len(categories), loss_fct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masa\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = transformers.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EvalPrediction\n",
    "from typing import Dict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "    # res.predictions, res.label_idsはnumpyのarray\n",
    "    pred = res.predictions.argmax(axis=1)\n",
    "    target = res.label_ids\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./output/model',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    label_names=['judgement'],\n",
    "    lr_scheduler_type='constant',\n",
    "    metric_for_best_model='f1',\n",
    "    load_best_model_at_end=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masa\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 19001\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 237600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25173e96fcd34c3e9e405a37ce2bc23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 4072\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1261, 'learning_rate': 5e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37a6b13347741339f2cbe56ec326c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./output/model\\checkpoint-2376\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12867233157157898, 'eval_precision': 0.4867387033398821, 'eval_recall': 0.5, 'eval_f1': 0.49328023892483824, 'eval_runtime': 73.3759, 'eval_samples_per_second': 55.495, 'eval_steps_per_second': 6.937, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./output/model\\checkpoint-2376\\tokenizer_config.json\n",
      "Special tokens file saved in ./output/model\\checkpoint-2376\\special_tokens_map.json\n",
      "Deleting older checkpoint [output\\model\\checkpoint-2] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4072\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1229, 'learning_rate': 5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3833d7e01d6048bcb65ca01932649487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./output/model\\checkpoint-4752\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13883720338344574, 'eval_precision': 0.4867387033398821, 'eval_recall': 0.5, 'eval_f1': 0.49328023892483824, 'eval_runtime': 71.8394, 'eval_samples_per_second': 56.682, 'eval_steps_per_second': 7.085, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./output/model\\checkpoint-4752\\tokenizer_config.json\n",
      "Special tokens file saved in ./output/model\\checkpoint-4752\\special_tokens_map.json\n",
      "Deleting older checkpoint [output\\model\\checkpoint-6] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4072\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1228, 'learning_rate': 5e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1a56a024174308b4a989afce692ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\masa\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./output/model\\checkpoint-7128\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14664702117443085, 'eval_precision': 0.4867387033398821, 'eval_recall': 0.5, 'eval_f1': 0.49328023892483824, 'eval_runtime': 73.5337, 'eval_samples_per_second': 55.376, 'eval_steps_per_second': 6.922, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./output/model\\checkpoint-7128\\tokenizer_config.json\n",
      "Special tokens file saved in ./output/model\\checkpoint-7128\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'output\\\\model\\\\checkpoint-2376' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 15\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStoppingCallback\n\u001b[0;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      6\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:1521\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1518\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1519\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1520\u001b[0m )\n\u001b[1;32m-> 1521\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1522\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1523\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1524\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1525\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1526\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:1855\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1852\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1854\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1855\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[0;32m   1858\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1859\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2069\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2068\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2069\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[0;32m   2070\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2232\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2230\u001b[0m \u001b[39m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2232\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rotate_checkpoints(use_mtime\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, output_dir\u001b[39m=\u001b[39;49mrun_dir)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2730\u001b[0m, in \u001b[0;36mTrainer._rotate_checkpoints\u001b[1;34m(self, use_mtime, output_dir)\u001b[0m\n\u001b[0;32m   2727\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   2729\u001b[0m \u001b[39m# Check if we should delete older checkpoint(s)\u001b[39;00m\n\u001b[1;32m-> 2730\u001b[0m checkpoints_sorted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sorted_checkpoints(use_mtime\u001b[39m=\u001b[39;49muse_mtime, output_dir\u001b[39m=\u001b[39;49moutput_dir)\n\u001b[0;32m   2731\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(checkpoints_sorted) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave_total_limit:\n\u001b[0;32m   2732\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py:2720\u001b[0m, in \u001b[0;36mTrainer._sorted_checkpoints\u001b[1;34m(self, output_dir, checkpoint_prefix, use_mtime)\u001b[0m\n\u001b[0;32m   2718\u001b[0m \u001b[39m# Make sure we don't delete the best model.\u001b[39;00m\n\u001b[0;32m   2719\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mbest_model_checkpoint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2720\u001b[0m     best_model_index \u001b[39m=\u001b[39m checkpoints_sorted\u001b[39m.\u001b[39;49mindex(\u001b[39mstr\u001b[39;49m(Path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mbest_model_checkpoint)))\n\u001b[0;32m   2721\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(best_model_index, \u001b[39mlen\u001b[39m(checkpoints_sorted) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m):\n\u001b[0;32m   2722\u001b[0m         checkpoints_sorted[i], checkpoints_sorted[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m checkpoints_sorted[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m], checkpoints_sorted[i]\n",
      "\u001b[1;31mValueError\u001b[0m: 'output\\\\model\\\\checkpoint-2376' is not in list"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=custom_collator,\n",
    "    compute_metrics=custom_compute_metrics,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': TrainingArguments(\n",
       " _n_gpu=1,\n",
       " adafactor=False,\n",
       " adam_beta1=0.9,\n",
       " adam_beta2=0.999,\n",
       " adam_epsilon=1e-08,\n",
       " auto_find_batch_size=False,\n",
       " bf16=False,\n",
       " bf16_full_eval=False,\n",
       " data_seed=None,\n",
       " dataloader_drop_last=False,\n",
       " dataloader_num_workers=0,\n",
       " dataloader_pin_memory=True,\n",
       " ddp_bucket_cap_mb=None,\n",
       " ddp_find_unused_parameters=None,\n",
       " ddp_timeout=1800,\n",
       " debug=[],\n",
       " deepspeed=None,\n",
       " disable_tqdm=False,\n",
       " do_eval=True,\n",
       " do_predict=False,\n",
       " do_train=False,\n",
       " eval_accumulation_steps=None,\n",
       " eval_delay=0,\n",
       " eval_steps=None,\n",
       " evaluation_strategy=epoch,\n",
       " fp16=False,\n",
       " fp16_backend=auto,\n",
       " fp16_full_eval=False,\n",
       " fp16_opt_level=O1,\n",
       " fsdp=[],\n",
       " fsdp_min_num_params=0,\n",
       " fsdp_transformer_layer_cls_to_wrap=None,\n",
       " full_determinism=False,\n",
       " gradient_accumulation_steps=1,\n",
       " gradient_checkpointing=False,\n",
       " greater_is_better=True,\n",
       " group_by_length=False,\n",
       " half_precision_backend=auto,\n",
       " hub_model_id=None,\n",
       " hub_private_repo=False,\n",
       " hub_strategy=every_save,\n",
       " hub_token=<HUB_TOKEN>,\n",
       " ignore_data_skip=False,\n",
       " include_inputs_for_metrics=False,\n",
       " jit_mode_eval=False,\n",
       " label_names=['judgement'],\n",
       " label_smoothing_factor=0.0,\n",
       " learning_rate=5e-05,\n",
       " length_column_name=length,\n",
       " load_best_model_at_end=True,\n",
       " local_rank=-1,\n",
       " log_level=-1,\n",
       " log_level_replica=-1,\n",
       " log_on_each_node=True,\n",
       " logging_dir=./output/model\\runs\\Oct08_15-30-19_DESKTOP-JTU963M,\n",
       " logging_first_step=False,\n",
       " logging_nan_inf_filter=True,\n",
       " logging_steps=500,\n",
       " logging_strategy=epoch,\n",
       " lr_scheduler_type=constant,\n",
       " max_grad_norm=1.0,\n",
       " max_steps=-1,\n",
       " metric_for_best_model=f1,\n",
       " mp_parameters=,\n",
       " no_cuda=False,\n",
       " num_train_epochs=3,\n",
       " optim=adamw_hf,\n",
       " output_dir=./output/model,\n",
       " overwrite_output_dir=False,\n",
       " past_index=-1,\n",
       " per_device_eval_batch_size=8,\n",
       " per_device_train_batch_size=8,\n",
       " prediction_loss_only=False,\n",
       " push_to_hub=False,\n",
       " push_to_hub_model_id=None,\n",
       " push_to_hub_organization=None,\n",
       " push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       " ray_scope=last,\n",
       " remove_unused_columns=False,\n",
       " report_to=['tensorboard'],\n",
       " resume_from_checkpoint=None,\n",
       " run_name=./output/model,\n",
       " save_on_each_node=False,\n",
       " save_steps=500,\n",
       " save_strategy=epoch,\n",
       " save_total_limit=1,\n",
       " seed=42,\n",
       " sharded_ddp=[],\n",
       " skip_memory_metrics=True,\n",
       " tf32=None,\n",
       " torchdynamo=None,\n",
       " tpu_metrics_debug=False,\n",
       " tpu_num_cores=None,\n",
       " use_ipex=False,\n",
       " use_legacy_prediction_loop=False,\n",
       " use_mps_device=False,\n",
       " warmup_ratio=0.0,\n",
       " warmup_steps=0,\n",
       " weight_decay=0.0,\n",
       " xpu_backend=None,\n",
       " ),\n",
       " 'hp_name': None,\n",
       " 'deepspeed': None,\n",
       " 'is_in_train': False,\n",
       " '_memory_tracker': <transformers.trainer_utils.TrainerMemoryTracker at 0x275808a7fd0>,\n",
       " 'model_init': None,\n",
       " 'is_model_parallel': False,\n",
       " 'sharded_ddp': None,\n",
       " 'fsdp': None,\n",
       " 'place_model_on_device': True,\n",
       " 'data_collator': <__main__.CustomCollator at 0x27576ed6670>,\n",
       " 'train_dataset': [{'abstract': \"The receptor for advanced glycation end-products (RAGE) is a pattern recognition receptor sensing endogenous stress signals associated with the development of various diseases  including diabetes  vascular complications  Alzheimer's disease and cancer. RAGE ligands include advanced glycation end-products  S100 proteins  high mobility group box 1 protein and amyloid ﾎｲ-peptides/fibrils. Their signalling through RAGE induces a sustained inflammation that accentuates tissue damage  thereby participating in disease progression. Receptor oligomerization appears to be a crucial parameter for the formation of active signalling complexes  although the precise mode of oligomerization remains unclear in the context of these various ligands. In the present study  we report the first crystal structure of the VC1C2 fragment of the RAGE ectodomain. This structure provides the first description of the C2 domain in the context of the entire ectodomain and supports the observation of its conformational freedom relative to the rigid VC1 domain tandem. In addition  we have obtained a new crystal structure of the RAGE VC1 fragment. The packing in both crystal structures reveals an association of the RAGE molecules through contacts between two V domains and the physiological relevance of this homodimerization mode is discussed. Based on homology with single-pass transmembrane receptors  we also suggest RAGE dimerization through a conserved GxxxG motif within its transmembrane domain. A multimodal homodimerization strategy of RAGE is proposed to form the structural basis for ligand-specific complex formation and signalling functions  as well as for RAGE-mediated cell adhesion. STRUCTURED DIGITAL ABSTRACT: hRAGE_VC1C2 and hRAGE_VC1C2 bind by x-ray crystallography (View interaction) hRAGE_VC1 and hRAGE_VC1 bind by x-ray crystallography (View interaction).\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Transesophageal Echocardiography Probe Sheath to Decrease Provider and Environment Contamination',\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'A woman with mild Covid-19 developed cervical adenopathy, being diagnosed of Epstein-Barr virus infectious mononucleosis. After a FNAP we demonstrate that SARS-CoV-2 is found in lymph nodes (LNs) even in mild disease along with a strong expansion of terminally differentiated effector memory CD4+T-cells , a cell population that is practically absent in LN. Copyright Â© The Author(s) 2020. Published by Oxford University Press for the Infectious Diseases Society of America. All rights reserved. For permissions, e-mail: journals.permissions@oup.com.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Here we present results from a survey on anti-SARS-CoV-2 seroprevalence in healthy blood donors from a low incidence COVID-19 area (Apulia region, South Eastern Italy). Among 904 subjects tested, only in 9 cases (0.99%) antibodies against SARS-CoV-2 were demonstrated. All the 9 seropositive patients were negative for the research of viral RNA by RT-PCR in nasopharyngeal swabs. These data, along with those recently reported from other countries, clearly show that we are very far from herd immunity and that the containment measures are at the moment the only realistic instrument we have to slow the spread of the pandemic. This article is protected by copyright. All rights reserved. Copyright This article is protected by copyright. All rights reserved.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"SARS-CoV-2 can be shed in the stool of patients in the recovery phase. Children show a longer shedding time than adults. We analyzed the possible causes of this finding and recommend that a negative stool sample be included in a patient's discharge criteria. Copyright Â© 2020. Published by Elsevier B.V.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Sixty children with Legg-Perthes disease (19)  bone tumor (27)  osteogenesis imperfecta (7)  osteomyelitis (5) and transient synovitis (2) were studied using 99mTc labeled diphosphonate. A number of benign or malign bone diseases of children need early detection in order to institute the best form--the fine form--of treatment. We recommend the bone scintigraphy in the initial screening of children with signs and symptoms of bone pathology.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Synthetic peptides capable of self-assembling into amyloid-like fibrillar structures are emerging as novel building blocks for biomaterials. They also serve as simple model systems to study the aggregation process involved in amyloid diseases. In this paper  we probe the structure and stability of fibrillar assemblies formed by two designed peptides P11-I (CH3-CO-Q2RQ5EQ2-NH2) and P11-II (CH3-CO-Q2RFQWQFEQ2-NH2). Our results suggest that the two peptides assemble by fundamentally different mechanisms to structures of different morphologies. Coulombic interactions between charged residues Arginine and Glutamate drive the self-assembly process for peptide P11-I while the hydrophobic effect appears to be the main driving force in the self-assembly of peptide P11-II.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Impact of Sars-Cov-2 Infection in Hematopoietic Transplant Patients: Experience from the Madrid Group',\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"Increasing evidence strongly supports the role of glial immunity in the pathogenesis of Alzheimer's disease (AD). To investigate such events we have developed cell systems mimicking the interactions between beta-amyloid precursor protein (APP)-expressing neurons and brain mononuclear phagocytes (MP; macrophages and microglia). MP were co-cultured with neuronal cells expressing wild type APP or familial AD-linked APP mutants. The latter was derived from recombinant adenoviral constructs. Neuronal APP processing products induced MP activation  reactive oxygen species  and neurotoxic activities. These occurred without the addition of pro-inflammatory cytokines and were reversed by depletion of amyloid beta-peptide (Abeta) and secreted APP (sAPP). Neurotoxic activities were diminished by superoxide dismutase mimetics and NMDA receptor inhibitors. Microglial glutamate secretion was suppressed by the cystine-glutamate antiporter inhibitor and its levels paralleled the depletion of sAPP and Abeta from conditioned media prepared from APP-expressing neurons. The excitotoxins from activated MP were potent enough to evoke recombinant NMDA receptor-mediated inward currents expressed in vitro in the Xenopus oocytes. These results demonstrate that neuronal APP-processing products can induce oxidative neurotoxicity through microglial activation.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Knowledge of lung ultrasound characteristics of coronavirus disease 2019 pneumonia might be useful for early diagnosis and clinical monitoring of patients, and lung ultrasound can help to control the spread of infection in healthcare settings. In this case report, a 36-year-old man with severe acute respiratory syndrome coronavirus 2 infection was diagnosed by reverse transcription-polymerase chain reaction testing of a nasopharyngeal swab. The lung ultrasound findings for this patient were the interstitial-alveolar damage showing bilateral, diffuse pleural line abnormalities, subpleural consolidations, white lung areas and thick, irregular vertical artifacts. When the patient recovered from the severe acute respiratory syndrome coronavirus 2 infection, lung ultrasound images showed a normal pleural line with A-lines regularly reverberating. Performing lung ultrasound at the bedside minimizes the need to move the patient, thus reducing the risk of spreading infection among healthcare staff. Lung ultrasound is useful for early diagnosis and evaluation of the severity of coronavirus disease 2019 pneumonia and for monitoring its progress over the course of the disease.Copyright Â© The Author(s) 2020.',\n",
       "   'judgement': 0}],\n",
       " 'eval_dataset': [{'abstract': \"Amyloid-beta peptide (Abeta) aggregate in senile plaque is a key characteristic of Alzheimer's disease (AD). Here  we show that phosphorylation of amyloid precursor protein (APP) on threonine 668 (P-APP) may play a role in APP metabolism. In AD brains  P-APP accumulates in large vesicular structures in afflicted hippocampal pyramidal neurons that costain with antibodies against endosome markers and the beta-secretase  BACE1. Western blot analysis reveals increased levels of T668-phosphorylated APP COOH-terminal fragments in hippocampal lysates from many AD but not control subjects. Importantly  P-APP cofractionates with endosome markers and BACE1 in an iodixanol gradient and displays extensive colocalization with BACE1 in rat primary cortical neurons. Furthermore  APP COOH-terminal fragments generated by BACE1 are preferentially phosphorylated on T668 verses those produced by alpha-secretase. The production of Abeta is significantly reduced when phosphorylation of T668 is either abolished by mutation or inhibited by T668 kinase inhibitors. Together  these results suggest that T668 phosphorylation may facilitate the BACE1 cleavage of APP to increase Abeta generation.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"In Alzheimer's disease (AD) neurofibrillary tangles (NFT) are strongly tau and ubiquitin immunopositive  and contain an aberrant form of ubiquitin derived from the ubiquitin-B gene denoted as UBB+1. We explored whether the tau-related NFT seen in another neurodegenerative disease  progressive supranuclear palsy (PSP)  also showed an accumulation of UBB+1. Three cases of PSP were examined immunohistochemically for tau protein  ubiquitin-protein conjugates and UBB+1 using single and double labelling. We conclude that UBB+1 is associated with compact globose tangles rather than dispersed accumulations of tau in PSP  showing that its presence is not unique to AD. We propose that aggregation of ubiquitinated proteins into compact inclusions in PSP might be due to inhibition of the degradation of multiubiquitinated proteins by ubiquitin chains containing proximal UBB+1 rather than normal ubiquitin.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"Thiazin red (TR)  a fluorochrome that has an affinity to fibrillary structures such as neurofibrillary tangles (NFTs) or senile plaques  was utilized to investigate assembly of tau protein into fibrils in tau-immunopositive neocortical neurons of corticobasal degeneration (CBD) and of Alzheimer's disease (AD). Double fluorescence with anti-paired helical filament monoclonal antibody (AT8) and TR was followed by either the Gallyas or Bodian silver impregnation method  which enabled a comparison of the staining features by three different methods on the same neuron. NFTs of AD were uniformly stained by TR and Gallyas method. Most of tau-immunopositive neurons of CBD were similarly stained by Gallyas method but barely or only weakly by TR or Bodian method  suggesting that tau in neocortical neurons of CBD is less liable to form fibrillary structures than in those of AD  easily distinguishable by TR staining. Clarifying the process of tau assembly using this fluorochrome will give a clue to understanding mechanisms of tau deposition  which may be different in various neurological disorders.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Background Spontaneous isolated posterior inferior cerebellar artery dissection (PICAD) is a very rare cause of ischemic stroke. Clinical and radiologic features of ischemic type of isolated spontaneous PICAD are not well established. Methods We consecutively enrolled patients who had spontaneous isolated PICAD confirmed by digital subtraction cerebral angiography. Clinical manifestation  magnetic resonance imaging (MRI)  and angiography were analyzed. Results Seven patients were diagnosed as ischemic type of spontaneous isolated PICAD. Patients experienced an occipital headache  followed by vertigo  postural imbalance  or Wallenberg syndrome. Six showed medullar  unilateral  or bilateral cerebellar infarctions on diffusion-weighted imaging (DWI). One presented with transient cerebellar ischemia and negative on DWI. T1-weighted imaging showed high signal intensity in posterior inferior cerebellar artery in only 1 patient. Susceptibility-weighted imaging (SWI) revealed hypointense signal with blooming effect in posterior inferior cerebellar artery in 5 patients. The modified Rankin Scale score at 3 months was 0 or 1 in all patients. Conclusions Clinical manifestations in ischemic type of spontaneous isolated PICAD were similar to those of intracranial vertebral artery dissection. Clinical course was relatively stable and benign. SWI was more helpful to suspect abnormality of posterior inferior cerebellar artery than conventional MRI or magnetic resonance angiography in our small series. Cerebral angiography is recommended in patients with clinically suspected spontaneous isolated PICAD for definite diagnosis. © 2014 by National Stroke Association.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Advances in neuroimaging: surgical localization',\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"The structure activity relationship of N'-benzylidene-benzohydrazide (NBB) binding to tau and paired helical filament (PHF) proteins as well as amyloid-ﾎｲ竄≫ｋ竄竄 fibrils indicate differential selectivity for these protein aggregates. The ability of the compounds to stain neurofibrillary tangles and senile plaques isolated from human AD brain was investigated histochemically. These studies resulted in several tau-PHF and amyloid-ﾎｲ竄≫ｋ竄竄 fibril selective ligands respectively. Supported by these results  we rationalized a model for the design of selective ligands for tau  PHF  and amyloid-ﾎｲ竄≫ｋ竄竄 fibrils.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'The effects of empathy loss in frontotemporal dementia (FTD) and Alzheimer disease (AD) on carer symptomatology were investigated. Carers of patients with 2 clinical subtypes of FTD (behavioral-variant FTD [bvFTD] = 18; semantic dementia [SD] = 14) and AD (n = 18) completed the Interpersonal Reactivity Index (IRI)  a standardized questionnaire of empathy as well as a measure of perceived burden (Zarit Burden Interview) and the quality of the marital relationship (Intimate Bond Measure). Patient ratings were also obtained on the IRI. Loss of empathy was most striking in the bvFTD group with a marked discrepancy observed between carer and patient ratings for change in emotional warmth and the ability to take the perspective of others. Empathy loss in bvFTD was associated with a loss of a caring marital relationship. Empathic deficits in SD were milder by comparison to bvFTD and correlated with disease severity and increased perceived carer burden. The behavioral pattern observed in AD differed from the FTD syndromes; deficits were observed only for measures of personal distress with carers reporting that patients were less able to handle emotionally evocative situations. Results highlight that changes in aspects of empathy differ across dementia syndromes and are associated with differing carer and clinical variables. These findings might be explained by the progression of atrophy in regions that are known to be critical for empathy and social behavior and has implications for the delivery and planning of services in dementia.',\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"Cognitive decline is a debilitating feature of most neurodegenerative diseases of the central nervous system  including Alzheimer's disease. The causes leading to such impairment are only poorly understood and effective treatments are slow to emerge. Here we show that cognitive capacities in the neurodegenerating brain are constrained by an epigenetic blockade of gene transcription that is potentially reversible. This blockade is mediated by histone deacetylase 2  which is increased by Alzheimer's-disease-related neurotoxic insults in vitro  in two mouse models of neurodegeneration and in patients with Alzheimer's disease. Histone deacetylase 2 associates with and reduces the histone acetylation of genes important for learning and memory  which show a concomitant decrease in expression. Importantly  reversing the build-up of histone deacetylase 2 by short-hairpin-RNA-mediated knockdown unlocks the repression of these genes  reinstates structural and synaptic plasticity  and abolishes neurodegeneration-associated memory impairments. These findings advocate for the development of selective inhibitors of histone deacetylase 2 and suggest that cognitive capacities following neurodegeneration are not entirely lost  but merely impaired by this epigenetic blockade.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': \"Cerebral amyloid angiopathy is a common pathological feature of patients with Alzheimer's disease (AD) and it is also the hallmark of individuals with a rare autosomal dominant disorder known as hereditary cerebral hemorrhage with amyloidosis-Dutch type. We have shown previously that wild type A(beta) peptides are anti-angiogenic both in vitro and in vivo and could contribute to the compromised cerebrovascular architecture observed in AD. In the present study  we investigated the potential anti-angiogenic activity of the Dutch A(beta)(1-40) (E22Q) peptide. We show that compared to wild type A(beta)  freshly solubilized Dutch A(beta) peptide more potently inhibits the formation of capillary structures induced by plating human brain microvascular endothelial cells onto a reconstituted basement membrane. Aggregated/fibrillar preparations of wild type A(beta) and Dutch A(beta) do not appear to be anti-angiogenic in this assay. The stronger anti-angiogenic activity of the Dutch A(beta) compared to wild type A(beta) appears to be related to the increased formation of low molecular weight A(beta) oligomers in the culture medium surrounding human brain microvascular endothelial cells. Using oligonucleotide microarray analysis of human brain microvascular endothelial cells  followed by a genome-scale computational analysis with the Ingenuity Pathways Knowledge Base  networks of genes affected by an anti-angiogenic dose of Dutch A(beta) were identified. This analysis highlights that several biological networks involved in angiogenesis  tumorigenesis  atherosclerosis  cellular migration and proliferation are disrupted in human brain microvascular endothelial cells exposed to Dutch A(beta). Altogether  these data provide new molecular clues regarding the pathological activity of Dutch A(beta) peptide in the cerebrovasculature.\",\n",
       "   'judgement': 0},\n",
       "  {'abstract': 'Large pleural effusions are typically associated with dyspnea and potential respiratory compromise. Experimental evidence suggests that with large effusions  increased intrapleural pressure may be transmitted to the pericardial space  resulting in impaired cardiac filling and reduced stroke volume. We report two cases in which large pleural collections were complicated by hypotension. The effusions were due to an infected right hepatic hydrothorax (Case 1) and a left malignant effusion (Case 2). Echocardiography demonstrated right and left ventricular diastolic collapse  respectively  confirming a diagnosis of cardiac tamponade. Large volume thoracentesis resulted in immediate hemodynamic improvement as demonstrated by a reduction in right ventricular and atrial pressures (Case 1) and echocardiographic resolution of left ventricular diastolic collapse (Case 2). These cases establish that large pleural effusions can cause hemodynamically significant cardiac tamponade. In addition  they illustrate how the demonstration of cardiac compressive physiology can significantly alter the therapeutic approach to large pleural effusions.',\n",
       "   'judgement': 0}],\n",
       " 'tokenizer': PreTrainedTokenizer(name_or_path='cl-tohoku/bert-base-japanese-whole-word-masking', vocab_size=32000, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       " 'model_wrapped': CustomNet(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (token_type_embeddings): Embedding(2, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): BertPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "   (loss_function): CrossEntropyLoss()\n",
       " ),\n",
       " 'model': CustomNet(\n",
       "   (bert): BertModel(\n",
       "     (embeddings): BertEmbeddings(\n",
       "       (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "       (position_embeddings): Embedding(512, 768)\n",
       "       (token_type_embeddings): Embedding(2, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): BertEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): BertLayer(\n",
       "           (attention): BertAttention(\n",
       "             (self): BertSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): BertSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): BertIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): BertOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): BertPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "   (loss_function): CrossEntropyLoss()\n",
       " ),\n",
       " 'compute_metrics': <function __main__.custom_compute_metrics(res: transformers.trainer_utils.EvalPrediction) -> Dict>,\n",
       " 'preprocess_logits_for_metrics': None,\n",
       " 'optimizer': AdamW (\n",
       " Parameter Group 0\n",
       "     betas: (0.9, 0.999)\n",
       "     correct_bias: True\n",
       "     eps: 1e-08\n",
       "     initial_lr: 5e-05\n",
       "     lr: 5e-05\n",
       "     weight_decay: 0.0\n",
       " \n",
       " Parameter Group 1\n",
       "     betas: (0.9, 0.999)\n",
       "     correct_bias: True\n",
       "     eps: 1e-08\n",
       "     initial_lr: 5e-05\n",
       "     lr: 5e-05\n",
       "     weight_decay: 0.0\n",
       " ),\n",
       " 'lr_scheduler': <torch.optim.lr_scheduler.LambdaLR at 0x275808b91f0>,\n",
       " 'callback_handler': <transformers.trainer_callback.CallbackHandler at 0x275808a7ee0>,\n",
       " '_loggers_initialized': False,\n",
       " '_signature_columns': None,\n",
       " 'use_apex': False,\n",
       " 'use_cuda_amp': False,\n",
       " 'use_cpu_amp': False,\n",
       " 'do_grad_scaling': False,\n",
       " 'label_smoother': None,\n",
       " 'state': TrainerState(epoch=3.0, global_step=6, max_steps=6, num_train_epochs=3, total_flos=0.0, log_history=[{'loss': 0.4008, 'learning_rate': 5e-05, 'epoch': 1.0, 'step': 2}, {'eval_loss': 0.03594436123967171, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.1945, 'eval_samples_per_second': 51.414, 'eval_steps_per_second': 10.283, 'epoch': 1.0, 'step': 2}, {'loss': 0.0191, 'learning_rate': 5e-05, 'epoch': 2.0, 'step': 4}, {'eval_loss': 0.0010150617454200983, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.1965, 'eval_samples_per_second': 50.897, 'eval_steps_per_second': 10.179, 'epoch': 2.0, 'step': 4}, {'loss': 0.0008, 'learning_rate': 5e-05, 'epoch': 3.0, 'step': 6}, {'eval_loss': 0.00022583393729291856, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_runtime': 0.1965, 'eval_samples_per_second': 50.896, 'eval_steps_per_second': 10.179, 'epoch': 3.0, 'step': 6}, {'train_runtime': 23.7026, 'train_samples_per_second': 1.266, 'train_steps_per_second': 0.253, 'total_flos': 0.0, 'train_loss': 0.14020715050476915, 'epoch': 3.0, 'step': 6}], best_metric=1.0, best_model_checkpoint='./output/model\\\\checkpoint-2', is_local_process_zero=True, is_world_process_zero=True, is_hyper_param_search=False, trial_name=None, trial_params=None),\n",
       " 'control': TrainerControl(should_training_stop=True, should_epoch_stop=False, should_save=False, should_evaluate=False, should_log=False),\n",
       " 'current_flos': 0,\n",
       " 'hp_search_backend': None,\n",
       " 'use_tune_checkpoints': False,\n",
       " 'label_names': ['judgement'],\n",
       " '_train_batch_size': 8,\n",
       " 'ctx_manager_torchdynamo': <contextlib.nullcontext at 0x275808b91c0>,\n",
       " '_trial': None,\n",
       " '_total_loss_scalar': 0.8412429030286148,\n",
       " '_globalstep_last_logged': 6}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_pickle('./input/livedoor_data.pickle')\n",
    "# カテゴリーのID列を付与しておく\n",
    "categories = df['category'].unique().tolist()\n",
    "category2id = {cat: categories.index(cat) for cat in categories}\n",
    "df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "df.sample(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c5e9d213741e57af941aa78a333f873168089e7713d62d465ad09d7150e1980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
